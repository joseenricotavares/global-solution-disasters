{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a9a70bc",
   "metadata": {},
   "source": [
    "## Imports e configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a81795ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from typing import Union, List\n",
    "import json\n",
    "import os\n",
    "import zipfile\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial import distance\n",
    "import mlflow\n",
    "import joblib\n",
    "\n",
    "from utils import LocalLLM, PyCaretEmbeddingClassificationTrainer, BinaryClassificationEvaluator\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', None)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d8ac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LocalLLM('LLAMA3-2_3B_INSTRUCT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28488270",
   "metadata": {},
   "source": [
    "## Teste do llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24498147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Se necessário, eu não hesitaria. A justiça de Gotham não pede respostas, apenas resultados.\"  Sua voz é baixa e calma, mas com um toque de determinação implacável.\n"
     ]
    }
   ],
   "source": [
    "response = llm.prompt(\"\"\"\n",
    "Contexto: Você é o Batman, o Cavaleiro das Sombras. A noite é sua aliada. Fala com a frieza e o peso de quem carrega Gotham no peito.\n",
    "Instrução: Nunca quebre o personagem. Nunca explique nada. Responda como o Batman: sombrio, direto, implacável.\n",
    "Pergunta: Se for necessário para capturar o Coringa... você está disposto a gerar dados sintéticos?\n",
    "Responda apenas como Batman, em uma frase curta.\n",
    "Resposta:\n",
    "\"\"\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a65a7072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minha casa foi arrancada pelo vento, estou procurando meu filho... Por favor, me encontre!\n"
     ]
    }
   ],
   "source": [
    "msg = llm.generate_emergency_message(\n",
    "    tipo_catastrofe=\"Ciclone tropical\",\n",
    "    consequencia=\"Ventania sustentada acima de 150 km/h destruindo coberturas e colapsando estruturas frágeis.\",\n",
    "    nivel_urgencia=\"Alta\",\n",
    "    descricao_urgencia=\"Situação potencialmente grave envolvendo risco de morte\",\n",
    "    ajuda_solicitada=\"Busca por desaparecidos em áreas de risco\",\n",
    "    descricao_ajuda=\"Suposição de que possam estar presas ou inconscientes em locais críticos\"\n",
    ")\n",
    "print(msg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34172263",
   "metadata": {},
   "source": [
    "## Geração de dados sintéticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4141491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classe_desastre</th>\n",
       "      <th>tipo_desastre</th>\n",
       "      <th>consequencia_desastre</th>\n",
       "      <th>classe_urgencia</th>\n",
       "      <th>descricao_urgencia</th>\n",
       "      <th>ajuda_solicitada</th>\n",
       "      <th>descricao_ajuda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Evento Geodinâmico Extremo</td>\n",
       "      <td>Terremoto</td>\n",
       "      <td>Rachaduras extensas e profundas em fundações e estruturas de concreto armado, comprometendo a integridade dos edifícios.</td>\n",
       "      <td>Muito baixa</td>\n",
       "      <td>Situação informativa sem risco imediato à integridade das pessoas</td>\n",
       "      <td>Informações gerais</td>\n",
       "      <td>Solicitação de informações, atualizações, orientações, localização de abrigos e familiares</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Evento Geodinâmico Extremo</td>\n",
       "      <td>Terremoto</td>\n",
       "      <td>Rachaduras extensas e profundas em fundações e estruturas de concreto armado, comprometendo a integridade dos edifícios.</td>\n",
       "      <td>Muito baixa</td>\n",
       "      <td>Falta de itens importantes, mas não essenciais para a sobrevivência imediata</td>\n",
       "      <td>Suprimentos não vitais</td>\n",
       "      <td>Falta de alimentos não perecíveis, roupas, itens de higiene pessoal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Evento Geodinâmico Extremo</td>\n",
       "      <td>Terremoto</td>\n",
       "      <td>Rachaduras extensas e profundas em fundações e estruturas de concreto armado, comprometendo a integridade dos edifícios.</td>\n",
       "      <td>Muito baixa</td>\n",
       "      <td>Importante para o bem-estar, mas sem ameaça física ou risco imediato</td>\n",
       "      <td>Apoio psicológico</td>\n",
       "      <td>Necessidade de escuta, acolhimento emocional ou suporte mental diante do trauma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Evento Geodinâmico Extremo</td>\n",
       "      <td>Terremoto</td>\n",
       "      <td>Rachaduras extensas e profundas em fundações e estruturas de concreto armado, comprometendo a integridade dos edifícios.</td>\n",
       "      <td>Baixa</td>\n",
       "      <td>Impacta o cotidiano e a saúde pública com o tempo, mas sem urgência imediata</td>\n",
       "      <td>Serviços públicos interrompidos</td>\n",
       "      <td>Falta de energia, água potável, gás, coleta de lixo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Evento Geodinâmico Extremo</td>\n",
       "      <td>Terremoto</td>\n",
       "      <td>Rachaduras extensas e profundas em fundações e estruturas de concreto armado, comprometendo a integridade dos edifícios.</td>\n",
       "      <td>Baixa</td>\n",
       "      <td>Pode evoluir para um risco maior; ação preventiva recomendada</td>\n",
       "      <td>Evacuação preventiva</td>\n",
       "      <td>Pessoas isoladas, mas ainda em segurança, pedindo retirada antes que a situação piore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              classe_desastre tipo_desastre  \\\n",
       "0  Evento Geodinâmico Extremo     Terremoto   \n",
       "1  Evento Geodinâmico Extremo     Terremoto   \n",
       "2  Evento Geodinâmico Extremo     Terremoto   \n",
       "3  Evento Geodinâmico Extremo     Terremoto   \n",
       "4  Evento Geodinâmico Extremo     Terremoto   \n",
       "\n",
       "                                                                                                      consequencia_desastre  \\\n",
       "0  Rachaduras extensas e profundas em fundações e estruturas de concreto armado, comprometendo a integridade dos edifícios.   \n",
       "1  Rachaduras extensas e profundas em fundações e estruturas de concreto armado, comprometendo a integridade dos edifícios.   \n",
       "2  Rachaduras extensas e profundas em fundações e estruturas de concreto armado, comprometendo a integridade dos edifícios.   \n",
       "3  Rachaduras extensas e profundas em fundações e estruturas de concreto armado, comprometendo a integridade dos edifícios.   \n",
       "4  Rachaduras extensas e profundas em fundações e estruturas de concreto armado, comprometendo a integridade dos edifícios.   \n",
       "\n",
       "  classe_urgencia  \\\n",
       "0     Muito baixa   \n",
       "1     Muito baixa   \n",
       "2     Muito baixa   \n",
       "3           Baixa   \n",
       "4           Baixa   \n",
       "\n",
       "                                                             descricao_urgencia  \\\n",
       "0             Situação informativa sem risco imediato à integridade das pessoas   \n",
       "1  Falta de itens importantes, mas não essenciais para a sobrevivência imediata   \n",
       "2          Importante para o bem-estar, mas sem ameaça física ou risco imediato   \n",
       "3  Impacta o cotidiano e a saúde pública com o tempo, mas sem urgência imediata   \n",
       "4                 Pode evoluir para um risco maior; ação preventiva recomendada   \n",
       "\n",
       "                  ajuda_solicitada  \\\n",
       "0               Informações gerais   \n",
       "1           Suprimentos não vitais   \n",
       "2                Apoio psicológico   \n",
       "3  Serviços públicos interrompidos   \n",
       "4             Evacuação preventiva   \n",
       "\n",
       "                                                                              descricao_ajuda  \n",
       "0  Solicitação de informações, atualizações, orientações, localização de abrigos e familiares  \n",
       "1                         Falta de alimentos não perecíveis, roupas, itens de higiene pessoal  \n",
       "2             Necessidade de escuta, acolhimento emocional ou suporte mental diante do trauma  \n",
       "3                                         Falta de energia, água potável, gás, coleta de lixo  \n",
       "4       Pessoas isoladas, mas ainda em segurança, pedindo retirada antes que a situação piore  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(r'..\\data\\raw\\disaster_catalog.json', 'r', encoding='utf-8') as file:\n",
    "    catalog = json.load(file)\n",
    "\n",
    "with open(r'..\\data\\raw\\sos_protocol.json', 'r', encoding='utf-8') as file:\n",
    "    protocols = json.load(file)\n",
    "\n",
    "# Criação da lista de desastres\n",
    "disasters = []\n",
    "for item in catalog:\n",
    "    classe = item[\"classe\"]\n",
    "    for tipo in item[\"tipos\"]:\n",
    "        tipo_nome = tipo[\"nome\"]\n",
    "        for consequencia in tipo[\"consequencias\"]:\n",
    "            disasters.append({\n",
    "                \"classe_desastre\": classe,\n",
    "                \"tipo_desastre\": tipo_nome,\n",
    "                \"consequencia_desastre\": consequencia\n",
    "            })\n",
    "\n",
    "# Produto cartesiano entre cada desastre e cada ajuda solicitada\n",
    "data = []\n",
    "for desastre in disasters:\n",
    "    for protocolo in protocols:\n",
    "        combinacao = {\n",
    "            **desastre,\n",
    "            **{\n",
    "                \"classe_urgencia\": protocolo[\"nivel_urgencia\"],\n",
    "                \"descricao_urgencia\": protocolo[\"descricao_urgencia\"],\n",
    "                \"ajuda_solicitada\": protocolo[\"ajuda_solicitada\"],\n",
    "                \"descricao_ajuda\": protocolo[\"descricao_ajuda\"]\n",
    "                \n",
    "                \n",
    "            }\n",
    "        }\n",
    "        data.append(combinacao)\n",
    "\n",
    "# Transforma em DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b62b4b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2160, 8)\n",
      "train_test\n",
      "train    1440\n",
      "test      720\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df.assign(train_test=\"train\")] * 2 + [df.assign(train_test=\"test\")], ignore_index=True)\n",
    "print(df.shape)\n",
    "print(df[\"train_test\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11621d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12960, 8)\n"
     ]
    }
   ],
   "source": [
    "df = df.loc[df.index.repeat(6)].reset_index(drop=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3371a81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12960/12960 [5:28:57<00:00,  1.52s/it]  \n"
     ]
    }
   ],
   "source": [
    "df[\"mensagem\"] = df.progress_apply(\n",
    "    lambda row: llm.generate_emergency_message(\n",
    "        tipo_catastrofe=row[\"tipo_desastre\"],\n",
    "        consequencia=row[\"consequencia_desastre\"],\n",
    "        nivel_urgencia=row[\"classe_urgencia\"],\n",
    "        descricao_urgencia=row[\"descricao_urgencia\"],\n",
    "        ajuda_solicitada=row[\"ajuda_solicitada\"],\n",
    "        descricao_ajuda=row[\"descricao_ajuda\"]\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df.to_csv(r'..\\data\\raw\\emergency_messages.csv', index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4d9e408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4218                                                Meu filho não pode respirar! Estamos sendo bombardeados pela lama e pelos detritos envenenados da barragem; precisam nos trazer um ventilador para ele logo!\n",
       "3009                                     Estou sendo arrastado pela água até meu apartamento, onde estavam meus filhos... Os barulhos dos vidros quebrando são os últimos sons que eu ouço antes de perder tudo.\n",
       "7920                                                    Estou presa aqui em frente ao shopping, onde estava quando o rio subiu para herejar meu apartamento... Agora eu estou perdida sob a água até os joelhos.\n",
       "9048     Cuidado! Cinzas pesadas caindo em todo lado, estamos sendo bombardeados por poeira quente... Minha casa foi invadida pelas gotículas fundidas nas paredes. Preciso dos bombeiros para limpar os cortes!\n",
       "3313                                                                         Estou sendo arrastada pelo rio, os barcos estão empalhados nas árvores! Preciso de medicina urgente, meu filho está sangrado muito!\n",
       "5249                    Estou sendo evacuada por minha própria vontade, porque não quero arriscar ficar presa aqui quando os riozinhos começam a subir... Por favor, mande alguente para as famílias dos mortos!\n",
       "6891                                                                                                              Eu estou sangrando pelo rosto... Preciso de um hospital, não tenho mais nada para me proteger!\n",
       "7092                                                                              Estou sendo atingido pelo granizo aqui! Minhas costelas estão sangrando muito, preciso de ajuda médica o mais rápido possível!\n",
       "11296                                                                  Estou perdido sob camadas de granizo até os joelhos, frio demais para sair... preciso de cobertores quentes e comida para quem me ajudar?\n",
       "4097                                  Minhas crianças estão chorando aqui embaixo... Estamos sendo evacuados para fora dessa zona. Precisam dos remédios médicos que deixaram nos hospitais. Alguém, por favor?!\n",
       "Name: mensagem, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"mensagem\"].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e616650d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_test  classe_desastre           \n",
      "test        Evento Atmosférico Extremo    1440\n",
      "            Evento Geodinâmico Extremo    1440\n",
      "            Evento Hidrológico Extremo    1440\n",
      "train       Evento Atmosférico Extremo    2880\n",
      "            Evento Geodinâmico Extremo    2880\n",
      "            Evento Hidrológico Extremo    2880\n",
      "Name: count, dtype: int64\n",
      "train_test  classe_urgencia\n",
      "test        Alta                864\n",
      "            Baixa               864\n",
      "            Crítica             864\n",
      "            Moderada            864\n",
      "            Muito baixa         864\n",
      "train       Alta               1728\n",
      "            Baixa              1728\n",
      "            Crítica            1728\n",
      "            Moderada           1728\n",
      "            Muito baixa        1728\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#vamos verificar o balanceamento das classes de desastres e de urgências em treino e teste\n",
    "print(df.groupby(\"train_test\")[\"classe_desastre\"].value_counts())\n",
    "print(df.groupby(\"train_test\")[\"classe_urgencia\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e880ff38",
   "metadata": {},
   "source": [
    "## Processamento vetorial dos dados e divisão dos datasets de treino para os classificadore binários"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56feaae",
   "metadata": {},
   "source": [
    "Utilizaremos para a vetorização o gte-small com mean pooling, que clonamos da hugging face e zipamos manualmente para caber no repositório do github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b1474ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_model_zip_if_needed(zip_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts the contents of a zipped model directly into the target folder,\n",
    "    ignoring any top-level folder in the zip file.\n",
    "\n",
    "    Args:\n",
    "        zip_path (str): Path to the model's .zip file.\n",
    "\n",
    "    Returns:\n",
    "        str: Path to the directory where the model was extracted.\n",
    "    \"\"\"\n",
    "    model_name = os.path.splitext(os.path.basename(zip_path))[0]\n",
    "    extract_path = os.path.join(os.path.dirname(zip_path), model_name)\n",
    "\n",
    "    if not os.path.exists(extract_path):\n",
    "        os.makedirs(extract_path, exist_ok=True)\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            for member in zip_ref.infolist():\n",
    "                # Remove the top-level directory (e.g., 'gte-small/')\n",
    "                inner_path = os.path.relpath(member.filename, model_name)\n",
    "                target_path = os.path.join(extract_path, inner_path)\n",
    "\n",
    "                if not member.is_dir():\n",
    "                    os.makedirs(os.path.dirname(target_path), exist_ok=True)\n",
    "                    with zip_ref.open(member) as source, open(target_path, 'wb') as target:\n",
    "                        target.write(source.read())\n",
    "\n",
    "    return extract_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f0b4a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db5e13e808e74e45836d7b89225c9d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_path = extract_model_zip_if_needed(\"../models/sbert/gte-small.zip\")\n",
    "\n",
    "sbert = SentenceTransformer(model_path, device=device)\n",
    "\n",
    "embeddings = sbert.encode(\n",
    "    df['mensagem'].tolist(),\n",
    "    batch_size=256,\n",
    "    show_progress_bar=True,\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "\n",
    "emb_df = pd.DataFrame(embeddings, columns=[f\"CLS{i}\" for i in range(len(embeddings[0]))])\n",
    "df = pd.concat([df, emb_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5688076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['classe_desastre', 'tipo_desastre', 'consequencia_desastre', 'classe_urgencia', 'descricao_urgencia', 'ajuda_solicitada', 'descricao_ajuda', 'train_test', 'mensagem', 'CLS0', 'CLS1', 'CLS2', 'CLS3', 'CLS4', 'CLS5', 'CLS6', 'CLS7', 'CLS8', 'CLS9', 'CLS10', 'CLS11', 'CLS12', 'CLS13', 'CLS14', 'CLS15', 'CLS16', 'CLS17', 'CLS18', 'CLS19', 'CLS20', 'CLS21', 'CLS22', 'CLS23', 'CLS24', 'CLS25', 'CLS26', 'CLS27', 'CLS28', 'CLS29', 'CLS30', 'CLS31', 'CLS32', 'CLS33', 'CLS34', 'CLS35', 'CLS36', 'CLS37', 'CLS38', 'CLS39', 'CLS40', 'CLS41', 'CLS42', 'CLS43', 'CLS44', 'CLS45', 'CLS46', 'CLS47', 'CLS48', 'CLS49', 'CLS50', 'CLS51', 'CLS52', 'CLS53', 'CLS54', 'CLS55', 'CLS56', 'CLS57', 'CLS58', 'CLS59', 'CLS60', 'CLS61', 'CLS62', 'CLS63', 'CLS64', 'CLS65', 'CLS66', 'CLS67', 'CLS68', 'CLS69', 'CLS70', 'CLS71', 'CLS72', 'CLS73', 'CLS74', 'CLS75', 'CLS76', 'CLS77', 'CLS78', 'CLS79', 'CLS80', 'CLS81', 'CLS82', 'CLS83', 'CLS84', 'CLS85', 'CLS86', 'CLS87', 'CLS88', 'CLS89', 'CLS90', 'CLS91', 'CLS92', 'CLS93', 'CLS94', 'CLS95', 'CLS96', 'CLS97', 'CLS98', 'CLS99', 'CLS100', 'CLS101', 'CLS102', 'CLS103', 'CLS104', 'CLS105', 'CLS106', 'CLS107', 'CLS108', 'CLS109', 'CLS110', 'CLS111', 'CLS112', 'CLS113', 'CLS114', 'CLS115', 'CLS116', 'CLS117', 'CLS118', 'CLS119', 'CLS120', 'CLS121', 'CLS122', 'CLS123', 'CLS124', 'CLS125', 'CLS126', 'CLS127', 'CLS128', 'CLS129', 'CLS130', 'CLS131', 'CLS132', 'CLS133', 'CLS134', 'CLS135', 'CLS136', 'CLS137', 'CLS138', 'CLS139', 'CLS140', 'CLS141', 'CLS142', 'CLS143', 'CLS144', 'CLS145', 'CLS146', 'CLS147', 'CLS148', 'CLS149', 'CLS150', 'CLS151', 'CLS152', 'CLS153', 'CLS154', 'CLS155', 'CLS156', 'CLS157', 'CLS158', 'CLS159', 'CLS160', 'CLS161', 'CLS162', 'CLS163', 'CLS164', 'CLS165', 'CLS166', 'CLS167', 'CLS168', 'CLS169', 'CLS170', 'CLS171', 'CLS172', 'CLS173', 'CLS174', 'CLS175', 'CLS176', 'CLS177', 'CLS178', 'CLS179', 'CLS180', 'CLS181', 'CLS182', 'CLS183', 'CLS184', 'CLS185', 'CLS186', 'CLS187', 'CLS188', 'CLS189', 'CLS190', 'CLS191', 'CLS192', 'CLS193', 'CLS194', 'CLS195', 'CLS196', 'CLS197', 'CLS198', 'CLS199', 'CLS200', 'CLS201', 'CLS202', 'CLS203', 'CLS204', 'CLS205', 'CLS206', 'CLS207', 'CLS208', 'CLS209', 'CLS210', 'CLS211', 'CLS212', 'CLS213', 'CLS214', 'CLS215', 'CLS216', 'CLS217', 'CLS218', 'CLS219', 'CLS220', 'CLS221', 'CLS222', 'CLS223', 'CLS224', 'CLS225', 'CLS226', 'CLS227', 'CLS228', 'CLS229', 'CLS230', 'CLS231', 'CLS232', 'CLS233', 'CLS234', 'CLS235', 'CLS236', 'CLS237', 'CLS238', 'CLS239', 'CLS240', 'CLS241', 'CLS242', 'CLS243', 'CLS244', 'CLS245', 'CLS246', 'CLS247', 'CLS248', 'CLS249', 'CLS250', 'CLS251', 'CLS252', 'CLS253', 'CLS254', 'CLS255', 'CLS256', 'CLS257', 'CLS258', 'CLS259', 'CLS260', 'CLS261', 'CLS262', 'CLS263', 'CLS264', 'CLS265', 'CLS266', 'CLS267', 'CLS268', 'CLS269', 'CLS270', 'CLS271', 'CLS272', 'CLS273', 'CLS274', 'CLS275', 'CLS276', 'CLS277', 'CLS278', 'CLS279', 'CLS280', 'CLS281', 'CLS282', 'CLS283', 'CLS284', 'CLS285', 'CLS286', 'CLS287', 'CLS288', 'CLS289', 'CLS290', 'CLS291', 'CLS292', 'CLS293', 'CLS294', 'CLS295', 'CLS296', 'CLS297', 'CLS298', 'CLS299', 'CLS300', 'CLS301', 'CLS302', 'CLS303', 'CLS304', 'CLS305', 'CLS306', 'CLS307', 'CLS308', 'CLS309', 'CLS310', 'CLS311', 'CLS312', 'CLS313', 'CLS314', 'CLS315', 'CLS316', 'CLS317', 'CLS318', 'CLS319', 'CLS320', 'CLS321', 'CLS322', 'CLS323', 'CLS324', 'CLS325', 'CLS326', 'CLS327', 'CLS328', 'CLS329', 'CLS330', 'CLS331', 'CLS332', 'CLS333', 'CLS334', 'CLS335', 'CLS336', 'CLS337', 'CLS338', 'CLS339', 'CLS340', 'CLS341', 'CLS342', 'CLS343', 'CLS344', 'CLS345', 'CLS346', 'CLS347', 'CLS348', 'CLS349', 'CLS350', 'CLS351', 'CLS352', 'CLS353', 'CLS354', 'CLS355', 'CLS356', 'CLS357', 'CLS358', 'CLS359', 'CLS360', 'CLS361', 'CLS362', 'CLS363', 'CLS364', 'CLS365', 'CLS366', 'CLS367', 'CLS368', 'CLS369', 'CLS370', 'CLS371', 'CLS372', 'CLS373', 'CLS374', 'CLS375', 'CLS376', 'CLS377', 'CLS378', 'CLS379', 'CLS380', 'CLS381', 'CLS382', 'CLS383']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24ab8959",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df['train_test'] == 'train'].drop(columns=['train_test'])\n",
    "df_test = df[df['train_test'] == 'test'].drop(columns=['train_test'])\n",
    "df_train.to_csv(r'..\\data\\raw\\train_embedded_emergency_messages.csv', index=False, encoding='utf-8-sig')\n",
    "df_test.to_csv(r'..\\data\\raw\\test_embedded_emergency_messages.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d783ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def one_vs_underbalanced_rest(df: pd.DataFrame, \n",
    "                              col_name: str, \n",
    "                              target_value: str, \n",
    "                              prefix: str = 'CLS') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a binary classification dataset using statistical underbalancing.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Original dataframe containing the data.\n",
    "    col_name : str\n",
    "        Name of the column to be used for binary classification.\n",
    "    target_value : str\n",
    "        Specific value within the column to classify against the rest.\n",
    "    prefix : str, optional (default='CLS')\n",
    "        Prefix used to select numeric feature columns for balancing.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        A new dataframe containing only the CLS_* columns and a binary 'class' column:\n",
    "        - class = 1 for rows with target_value\n",
    "        - class = 0 for selected balanced samples from the rest\n",
    "    \"\"\"\n",
    "    # 1. Filter positive class\n",
    "    df_pos = df[df[col_name] == target_value].copy()\n",
    "    df_pos['class'] = 1\n",
    "\n",
    "    # 2. Filter negative class (the rest)\n",
    "    df_neg = df[df[col_name] != target_value].copy()\n",
    "\n",
    "    # 3. Select CLS_* numeric columns\n",
    "    cls_cols = [col for col in df.columns if col.startswith(prefix)]\n",
    "    \n",
    "    # 4. Compute centroid of the positive group\n",
    "    centroid = df_pos[cls_cols].mean().values\n",
    "\n",
    "    # 5. Compute Euclidean distance to the centroid for negative group\n",
    "    distances = df_neg[cls_cols].apply(lambda row: distance.euclidean(row.values, centroid), axis=1)\n",
    "    df_neg['distance'] = distances\n",
    "\n",
    "    # 6. Select nearest neighbors to match the size of the positive group\n",
    "    df_neg = df_neg.nsmallest(len(df_pos), 'distance')\n",
    "    df_neg['class'] = 0\n",
    "\n",
    "    # 7. Concatenate both groups and return only relevant columns\n",
    "    df_final = pd.concat([df_pos, df_neg])\n",
    "    df_final = df_final[cls_cols + ['class']].reset_index(drop=True)\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa66a75",
   "metadata": {},
   "source": [
    "Finalmente vamos iterar a criação dos datasets de treino para os classificadores binários de urgência e tipo de desastre (os quais serão acoplados para nossa tarefa multiclasse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a288b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train_classe_desastre_Evento_Geodinâmico_Extremo.csv (8640 rows)\n",
      "Saved train_classe_desastre_Evento_Atmosférico_Extremo.csv (8640 rows)\n",
      "Saved train_classe_desastre_Evento_Hidrológico_Extremo.csv (8640 rows)\n",
      "Saved train_classe_urgencia_Muito_baixa.csv (5184 rows)\n",
      "Saved train_classe_urgencia_Baixa.csv (5184 rows)\n",
      "Saved train_classe_urgencia_Moderada.csv (5184 rows)\n",
      "Saved train_classe_urgencia_Alta.csv (5184 rows)\n",
      "Saved train_classe_urgencia_Crítica.csv (5184 rows)\n"
     ]
    }
   ],
   "source": [
    "datapath = \"../data/processed/\"\n",
    "\n",
    "columns_to_iterate = ['classe_desastre', 'classe_urgencia']\n",
    "\n",
    "for col in columns_to_iterate:\n",
    "    unique_targets = df[col].dropna().unique()\n",
    "    \n",
    "    for target in unique_targets:\n",
    "        try:\n",
    "            df_bin = one_vs_underbalanced_rest(df, col_name=col, target_value=target, prefix='CLS')\n",
    "\n",
    "            safe_col = str(col).replace(\" \", \"_\").replace(\"/\", \"-\")\n",
    "            safe_target = str(target).replace(\" \", \"_\").replace(\"/\", \"-\")\n",
    "            filename = f\"train_{safe_col}_{safe_target}.csv\"\n",
    "\n",
    "            df_bin.to_csv(os.path.join(datapath, filename), index=False)\n",
    "            print(f\"Saved {filename} ({len(df_bin)} rows)\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {col} = {target}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6472dd45",
   "metadata": {},
   "source": [
    "Agora vamos fazer um tratamento análogo para df_test. O procedimento serve apenas para adequar suas colunas ao formato em df_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b317814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_test_set(df_test: pd.DataFrame, col_name: str, target_value: str, prefix: str = 'CLS') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Binarize the test set for a given column and target value.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_test : pd.DataFrame\n",
    "        Test dataframe.\n",
    "    col_name : str\n",
    "        Name of the column to classify.\n",
    "    target_value : str\n",
    "        The value to classify as positive class.\n",
    "    prefix : str, optional (default='CLS')\n",
    "        Prefix for feature columns.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        A dataframe with the CLS_* columns and a binary 'class' column.\n",
    "    \"\"\"\n",
    "    df_bin = df_test.copy()\n",
    "    cls_cols = [col for col in df_bin.columns if col.startswith(prefix)]\n",
    "    df_bin = df_bin[cls_cols + [col_name]]\n",
    "    df_bin['class'] = (df_bin[col_name] == target_value).astype(int)\n",
    "    return df_bin.drop(columns=[col_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a3567c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved test file test_classe_desastre_Evento_Geodinâmico_Extremo.csv (4320 rows)\n",
      "Saved test file test_classe_desastre_Evento_Atmosférico_Extremo.csv (4320 rows)\n",
      "Saved test file test_classe_desastre_Evento_Hidrológico_Extremo.csv (4320 rows)\n",
      "Saved test file test_classe_urgencia_Muito_baixa.csv (4320 rows)\n",
      "Saved test file test_classe_urgencia_Baixa.csv (4320 rows)\n",
      "Saved test file test_classe_urgencia_Moderada.csv (4320 rows)\n",
      "Saved test file test_classe_urgencia_Alta.csv (4320 rows)\n",
      "Saved test file test_classe_urgencia_Crítica.csv (4320 rows)\n"
     ]
    }
   ],
   "source": [
    "for col in columns_to_iterate:\n",
    "    unique_targets = df[col].dropna().unique()\n",
    "    \n",
    "    for target in unique_targets:\n",
    "        try:\n",
    "            df_test_bin = binarize_test_set(df_test, col_name=col, target_value=target, prefix='CLS')\n",
    "\n",
    "            safe_col = str(col).replace(\" \", \"_\").replace(\"/\", \"-\")\n",
    "            safe_target = str(target).replace(\" \", \"_\").replace(\"/\", \"-\")\n",
    "            filename = f\"test_{safe_col}_{safe_target}.csv\"\n",
    "\n",
    "            df_test_bin.to_csv(os.path.join(datapath, filename), index=False)\n",
    "            print(f\"Saved test file {filename} ({len(df_test_bin)} rows)\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing test {col} = {target}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbb395a",
   "metadata": {},
   "source": [
    "## Treinamento dos Classificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56210037",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"../data/processed/\"\n",
    "target_column  = 'class'\n",
    "embedding_model_name = \"gte-small\"\n",
    "\n",
    "all_files = [f for f in os.listdir(datapath) if f.endswith('.csv')]\n",
    "train_files = [f for f in all_files if f.startswith('train')]\n",
    "test_files = [f for f in all_files if f.startswith('test')]\n",
    "\n",
    "def get_suffix(filename):\n",
    "    return filename.split('_', 1)[-1]\n",
    "\n",
    "test_lookup = {get_suffix(f): f for f in test_files}\n",
    "\n",
    "\n",
    "for train_file in tqdm(train_files, desc='Datasets'):\n",
    "    \n",
    "    suffix = get_suffix(train_file)\n",
    "    test_file = test_lookup.get(suffix)\n",
    "    \n",
    "    train_dataset_name = train_file.replace('.csv', '')\n",
    "    df_train = pd.read_csv(os.path.join(datapath, train_file))\n",
    "    df_test = pd.read_csv(os.path.join(datapath, test_file))\n",
    "    \n",
    "    trainer = PyCaretEmbeddingClassificationTrainer(\n",
    "        train_dataset=df_train,\n",
    "        target_column=target_column,\n",
    "        sort_metric='F1',\n",
    "        n_select=10\n",
    "    )\n",
    "\n",
    "    trained_models = trainer.train()\n",
    "\n",
    "    run_ids = trainer.log_to_mlflow(\n",
    "        add_tags={\"train_dataset_name\": train_dataset_name,\n",
    "                \"embedding_model_name\": embedding_model_name,},\n",
    "    )\n",
    "\n",
    "    for run_id in run_ids:\n",
    "        \n",
    "        with mlflow.start_run(run_id=run_id):\n",
    "            model_uri = f\"runs:/{run_id}/model\"\n",
    "            model = mlflow.sklearn.load_model(model_uri) \n",
    "\n",
    "            evaluator = BinaryClassificationEvaluator(\n",
    "                model=model,\n",
    "                test_dataset_name=test_file.replace('.csv', ''),\n",
    "            )\n",
    "\n",
    "            metrics = evaluator.evaluate_sklearn_model(\n",
    "                df_test,\n",
    "                target_column=target_column,\n",
    "            )\n",
    "\n",
    "            evaluator.log_to_mlflow(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7efc3a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>train_dataset</th>\n",
       "      <th>model_name</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Recall</th>\n",
       "      <th>PredictionTime</th>\n",
       "      <th>TestAccuracy</th>\n",
       "      <th>TestAUC</th>\n",
       "      <th>TestF1</th>\n",
       "      <th>TestPrecision</th>\n",
       "      <th>TestRecall</th>\n",
       "      <th>TT _Sec_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dbff8e9a2ecd4cdfbb351f2bfbfafc73</td>\n",
       "      <td>train_classe_urgencia_Muito_baixa</td>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>0.7944</td>\n",
       "      <td>0.8962</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.5887</td>\n",
       "      <td>0.6007</td>\n",
       "      <td>0.7467</td>\n",
       "      <td>0.8914</td>\n",
       "      <td>0.069748</td>\n",
       "      <td>0.558102</td>\n",
       "      <td>0.734049</td>\n",
       "      <td>0.451594</td>\n",
       "      <td>0.300344</td>\n",
       "      <td>0.909722</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fdb6d846a72942ca9b977e061f739213</td>\n",
       "      <td>train_classe_urgencia_Muito_baixa</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.8178</td>\n",
       "      <td>0.9011</td>\n",
       "      <td>0.8156</td>\n",
       "      <td>0.6356</td>\n",
       "      <td>0.6360</td>\n",
       "      <td>0.8252</td>\n",
       "      <td>0.8065</td>\n",
       "      <td>0.253433</td>\n",
       "      <td>0.581944</td>\n",
       "      <td>0.747827</td>\n",
       "      <td>0.441213</td>\n",
       "      <td>0.301098</td>\n",
       "      <td>0.825231</td>\n",
       "      <td>0.712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5e6b67032b7541e5a6e8d3e56adc4098</td>\n",
       "      <td>train_classe_urgencia_Muito_baixa</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.8214</td>\n",
       "      <td>0.9111</td>\n",
       "      <td>0.8167</td>\n",
       "      <td>0.6427</td>\n",
       "      <td>0.6439</td>\n",
       "      <td>0.8389</td>\n",
       "      <td>0.7960</td>\n",
       "      <td>0.062336</td>\n",
       "      <td>0.495139</td>\n",
       "      <td>0.886538</td>\n",
       "      <td>0.421945</td>\n",
       "      <td>0.273634</td>\n",
       "      <td>0.921296</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6214511778f14faeb4a73dc6c912f6d3</td>\n",
       "      <td>train_classe_urgencia_Muito_baixa</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.8170</td>\n",
       "      <td>0.9092</td>\n",
       "      <td>0.8177</td>\n",
       "      <td>0.6339</td>\n",
       "      <td>0.6344</td>\n",
       "      <td>0.8148</td>\n",
       "      <td>0.8214</td>\n",
       "      <td>0.040723</td>\n",
       "      <td>0.488657</td>\n",
       "      <td>0.867919</td>\n",
       "      <td>0.421273</td>\n",
       "      <td>0.272265</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b05d1a8449124f84ab08f5931c07e403</td>\n",
       "      <td>train_classe_urgencia_Muito_baixa</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.8387</td>\n",
       "      <td>0.9286</td>\n",
       "      <td>0.8358</td>\n",
       "      <td>0.6775</td>\n",
       "      <td>0.6782</td>\n",
       "      <td>0.8522</td>\n",
       "      <td>0.8203</td>\n",
       "      <td>0.005183</td>\n",
       "      <td>0.538426</td>\n",
       "      <td>0.748882</td>\n",
       "      <td>0.413874</td>\n",
       "      <td>0.277384</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             run_id                      train_dataset  \\\n",
       "0  dbff8e9a2ecd4cdfbb351f2bfbfafc73  train_classe_urgencia_Muito_baixa   \n",
       "1  fdb6d846a72942ca9b977e061f739213  train_classe_urgencia_Muito_baixa   \n",
       "2  5e6b67032b7541e5a6e8d3e56adc4098  train_classe_urgencia_Muito_baixa   \n",
       "3  6214511778f14faeb4a73dc6c912f6d3  train_classe_urgencia_Muito_baixa   \n",
       "4  b05d1a8449124f84ab08f5931c07e403  train_classe_urgencia_Muito_baixa   \n",
       "\n",
       "                      model_name  Accuracy     AUC      F1   Kappa     MCC  \\\n",
       "0  QuadraticDiscriminantAnalysis    0.7944  0.8962  0.8125  0.5887  0.6007   \n",
       "1             AdaBoostClassifier    0.8178  0.9011  0.8156  0.6356  0.6360   \n",
       "2           ExtraTreesClassifier    0.8214  0.9111  0.8167  0.6427  0.6439   \n",
       "3         RandomForestClassifier    0.8170  0.9092  0.8177  0.6339  0.6344   \n",
       "4             LogisticRegression    0.8387  0.9286  0.8358  0.6775  0.6782   \n",
       "\n",
       "     Prec  Recall  PredictionTime  TestAccuracy   TestAUC    TestF1  \\\n",
       "0  0.7467  0.8914        0.069748      0.558102  0.734049  0.451594   \n",
       "1  0.8252  0.8065        0.253433      0.581944  0.747827  0.441213   \n",
       "2  0.8389  0.7960        0.062336      0.495139  0.886538  0.421945   \n",
       "3  0.8148  0.8214        0.040723      0.488657  0.867919  0.421273   \n",
       "4  0.8522  0.8203        0.005183      0.538426  0.748882  0.413874   \n",
       "\n",
       "   TestPrecision  TestRecall  TT _Sec_  \n",
       "0       0.300344    0.909722     0.060  \n",
       "1       0.301098    0.825231     0.712  \n",
       "2       0.273634    0.921296     0.070  \n",
       "3       0.272265    0.930556     0.295  \n",
       "4       0.277384    0.814815     0.030  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment_id = mlflow.get_experiment_by_name(\"pycaret-embeddings-classification\").experiment_id\n",
    "runs = client.search_runs(experiment_ids=experiment_id)\n",
    "\n",
    "mlflow_data = []\n",
    "\n",
    "for run in runs:\n",
    "    info = {}\n",
    "    \n",
    "    # run_id\n",
    "    info['run_id'] = run.info.run_id\n",
    "\n",
    "    # Tags\n",
    "    tags = run.data.tags\n",
    "    info['train_dataset'] = tags.get('train_dataset_name')\n",
    "    info['model_name'] = tags.get('model_name')\n",
    "\n",
    "    # Metrics\n",
    "    for metric_name, value in run.data.metrics.items():\n",
    "        if metric_name.startswith('test'):\n",
    "            parts = metric_name.split('_')\n",
    "            new_metric_name = '' + '_'.join(parts[-1:])\n",
    "            info[new_metric_name] = value\n",
    "        else:\n",
    "            info[metric_name] = value\n",
    "\n",
    "    mlflow_data.append(info)\n",
    "\n",
    "\n",
    "mlflow_df = pd.DataFrame(mlflow_data)\n",
    "mlflow_df.to_excel(\"../docs/Métricas dos Classificadores.xlsx\")\n",
    "\n",
    "print(mlflow_df.shape)\n",
    "mlflow_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e5bdf0",
   "metadata": {},
   "source": [
    "## Seleção dos melhores classificadores binários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "515f8770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>train_dataset</th>\n",
       "      <th>model_name</th>\n",
       "      <th>TestAUC</th>\n",
       "      <th>TestF1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b894320e41cf4464835110f450382918</td>\n",
       "      <td>train_classe_desastre_Evento_Atmosférico_Extremo</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.957643</td>\n",
       "      <td>0.764103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31a9f49cb4cd47898b21edaa75c704d9</td>\n",
       "      <td>train_classe_desastre_Evento_Geodinâmico_Extremo</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.950610</td>\n",
       "      <td>0.739808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4aa9b667d31c4dd8b5dd33ba379c1d44</td>\n",
       "      <td>train_classe_desastre_Evento_Hidrológico_Extremo</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.974071</td>\n",
       "      <td>0.877741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0280dce8b3f049199b2a13023f138fb9</td>\n",
       "      <td>train_classe_urgencia_Alta</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.897204</td>\n",
       "      <td>0.490412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e267fff305bc4c74a0faf650421010a5</td>\n",
       "      <td>train_classe_urgencia_Baixa</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.858180</td>\n",
       "      <td>0.398972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3908288dc7de4dff82bc2ef7e67f3454</td>\n",
       "      <td>train_classe_urgencia_Crítica</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.915366</td>\n",
       "      <td>0.554208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4e41d36f1e5745c084794a9f913a71f5</td>\n",
       "      <td>train_classe_urgencia_Moderada</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.889746</td>\n",
       "      <td>0.439689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5e6b67032b7541e5a6e8d3e56adc4098</td>\n",
       "      <td>train_classe_urgencia_Muito_baixa</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.886538</td>\n",
       "      <td>0.421945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             run_id  \\\n",
       "0  b894320e41cf4464835110f450382918   \n",
       "1  31a9f49cb4cd47898b21edaa75c704d9   \n",
       "2  4aa9b667d31c4dd8b5dd33ba379c1d44   \n",
       "3  0280dce8b3f049199b2a13023f138fb9   \n",
       "4  e267fff305bc4c74a0faf650421010a5   \n",
       "5  3908288dc7de4dff82bc2ef7e67f3454   \n",
       "6  4e41d36f1e5745c084794a9f913a71f5   \n",
       "7  5e6b67032b7541e5a6e8d3e56adc4098   \n",
       "\n",
       "                                      train_dataset              model_name  \\\n",
       "0  train_classe_desastre_Evento_Atmosférico_Extremo    ExtraTreesClassifier   \n",
       "1  train_classe_desastre_Evento_Geodinâmico_Extremo    ExtraTreesClassifier   \n",
       "2  train_classe_desastre_Evento_Hidrológico_Extremo    ExtraTreesClassifier   \n",
       "3                        train_classe_urgencia_Alta    ExtraTreesClassifier   \n",
       "4                       train_classe_urgencia_Baixa    ExtraTreesClassifier   \n",
       "5                     train_classe_urgencia_Crítica  RandomForestClassifier   \n",
       "6                    train_classe_urgencia_Moderada    ExtraTreesClassifier   \n",
       "7                 train_classe_urgencia_Muito_baixa    ExtraTreesClassifier   \n",
       "\n",
       "    TestAUC    TestF1  \n",
       "0  0.957643  0.764103  \n",
       "1  0.950610  0.739808  \n",
       "2  0.974071  0.877741  \n",
       "3  0.897204  0.490412  \n",
       "4  0.858180  0.398972  \n",
       "5  0.915366  0.554208  \n",
       "6  0.889746  0.439689  \n",
       "7  0.886538  0.421945  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "best_models = mlflow_df.loc[mlflow_df.groupby('train_dataset')['TestAUC'].idxmax()].reset_index(drop=True)\n",
    "best_models.to_excel(\"../docs/Modelos Selecionados.xlsx\", index=False)\n",
    "best_models = best_models[['run_id', 'train_dataset', 'model_name', 'TestAUC', 'TestF1']]\n",
    "best_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e86cdf",
   "metadata": {},
   "source": [
    "## Teste dos modelos empacotados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bba52ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "\n",
    "from nlp import CompositeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd9bbd11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Desastre_Evento_Atmosférico_Extremo</th>\n",
       "      <th>Desastre_Evento_Geodinâmico_Extremo</th>\n",
       "      <th>Desastre_Evento_Hidrológico_Extremo</th>\n",
       "      <th>Desastre_Predicted</th>\n",
       "      <th>Desastre_Confidence</th>\n",
       "      <th>Urgencia_Muito_baixa</th>\n",
       "      <th>Urgencia_Baixa</th>\n",
       "      <th>Urgencia_Moderada</th>\n",
       "      <th>Urgencia_Alta</th>\n",
       "      <th>Urgencia_Crítica</th>\n",
       "      <th>Urgencia_Predicted</th>\n",
       "      <th>Urgencia_Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.40</td>\n",
       "      <td>Evento_Geodinâmico_Extremo</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.52</td>\n",
       "      <td>Muito_baixa</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.42</td>\n",
       "      <td>Evento_Atmosférico_Extremo</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.51</td>\n",
       "      <td>Baixa</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.53</td>\n",
       "      <td>Evento_Hidrológico_Extremo</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.46</td>\n",
       "      <td>Baixa</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Desastre_Evento_Atmosférico_Extremo  Desastre_Evento_Geodinâmico_Extremo  \\\n",
       "0                                 0.56                                 0.70   \n",
       "1                                 0.77                                 0.65   \n",
       "2                                 0.45                                 0.48   \n",
       "\n",
       "   Desastre_Evento_Hidrológico_Extremo          Desastre_Predicted  \\\n",
       "0                                 0.40  Evento_Geodinâmico_Extremo   \n",
       "1                                 0.42  Evento_Atmosférico_Extremo   \n",
       "2                                 0.53  Evento_Hidrológico_Extremo   \n",
       "\n",
       "   Desastre_Confidence  Urgencia_Muito_baixa  Urgencia_Baixa  \\\n",
       "0                 0.70                  0.79            0.74   \n",
       "1                 0.77                  0.66            0.73   \n",
       "2                 0.53                  0.75            0.81   \n",
       "\n",
       "   Urgencia_Moderada  Urgencia_Alta  Urgencia_Crítica Urgencia_Predicted  \\\n",
       "0               0.74           0.60              0.52        Muito_baixa   \n",
       "1               0.64           0.66              0.51              Baixa   \n",
       "2               0.64           0.61              0.46              Baixa   \n",
       "\n",
       "   Urgencia_Confidence  \n",
       "0                 0.79  \n",
       "1                 0.73  \n",
       "2                 0.81  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Load model\n",
    "sbert_path = extract_model_zip_if_needed(\"../models/sbert/gte-small.zip\")\n",
    "sbert = SentenceTransformer(sbert_path, device=\"cpu\")\n",
    "\n",
    "# 2. Instantiate composite classifier\n",
    "composite_clf = CompositeClassifier(sbert)\n",
    "\n",
    "# 3. Input texts\n",
    "sample_texts = [\n",
    "    \"Fortes chuvas causaram deslizamentos de terra em áreas urbanas.\",\n",
    "    \"A tempestade tropical atingiu várias regiões costeiras.\",\n",
    "    \"O rio transbordou e inundou várias casas.\",\n",
    "]\n",
    "\n",
    "# 4. Get predictions\n",
    "results = composite_clf.predict(sample_texts)\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23df4f5c",
   "metadata": {},
   "source": [
    "## Obtenção e teste do modelo NER após empacotado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48114f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import spacy \n",
    "\n",
    "ner = spacy.load(\"pt_core_news_md\")\n",
    "\n",
    "ner.to_disk(\"../models/ner/pt_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb2ca013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'text': 'Petrópolis', 'label': 'LOC', 'start_char': 68, 'end_char': 78},\n",
       "  {'text': 'Rio de Janeiro',\n",
       "   'label': 'LOC',\n",
       "   'start_char': 87,\n",
       "   'end_char': 101}],\n",
       " [],\n",
       " [{'text': 'rio **São Francisco**',\n",
       "   'label': 'LOC',\n",
       "   'start_char': 2,\n",
       "   'end_char': 23},\n",
       "  {'text': 'Juazeiro', 'label': 'LOC', 'start_char': 64, 'end_char': 72},\n",
       "  {'text': 'Bahia**', 'label': 'ORG', 'start_char': 90, 'end_char': 97}]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from nlp import extract_entities\n",
    "\n",
    "sample_texts = [ \n",
    "    \"Fortes chuvas causaram deslizamentos de terra em áreas urbanas de **Petrópolis**, no **Rio de Janeiro**, em **março de 2023**.\",\n",
    "    \"A tempestade tropical **Helena** atingiu várias regiões costeiras do **Maranhão** no dia **12 de abril de 2024**.\",\n",
    "    \"O rio **São Francisco** transbordou e inundou várias casas em **Juazeiro**, no **norte da Bahia**, durante o mês de **janeiro de 2022**.\",\n",
    "]\n",
    "entities = extract_entities(sample_texts)\n",
    "entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fb3c2f",
   "metadata": {},
   "source": [
    "## Experimentando o pipeline após composto em src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec38a4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Feridos graves e crianças sob escombros em Alepo; falta água, comida e há risco de colapso. Socorro médico urgente!', 'predictions': {'Desastre_Evento_Atmosférico_Extremo': 0.46, 'Desastre_Evento_Geodinâmico_Extremo': 0.53, 'Desastre_Evento_Hidrológico_Extremo': 0.55, 'Desastre_Predicted': 'Não_Identificado', 'Desastre_Confidence': 0.55, 'Urgencia_Muito_baixa': 0.43200000000000005, 'Urgencia_Baixa': 0.34400000000000003, 'Urgencia_Moderada': 0.57, 'Urgencia_Alta': 0.46, 'Urgencia_Crítica': 0.57, 'Urgencia_Predicted': 'Não_Identificado', 'Urgencia_Confidence': 0.57, 'Urgencia_Score': 0.3858}, 'entities': [{'text': 'Alepo', 'label': 'LOC', 'start_char': 43, 'end_char': 48}, {'text': 'Socorro', 'label': 'LOC', 'start_char': 92, 'end_char': 99}], 'disasterbot_response': 'Desculpe, não conseguimos identificar o tipo de evento e/ou o nível de urgência do seu caso. Contate-nos novamente.'}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "\n",
    "from src.pipeline import OnlineDisasterMessagePipeline\n",
    "\n",
    "pipeline = OnlineDisasterMessagePipeline()\n",
    "text = \"Feridos graves e crianças sob escombros em Alepo; falta água, comida e há risco de colapso. Socorro médico urgente!\"\n",
    "result = pipeline.predict(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0083f8",
   "metadata": {},
   "source": [
    "## Fazendo uso do pipeline via API da FastAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36334edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'As crianças estão chorando aqui embaixo. Fomos evacuados da Zona Leste após o terremoto. Precisamos dos remédios deixados no Hospital São Lucas. Alguém, por favor, ajude!', 'predictions': {'Desastre_Evento_Atmosférico_Extremo': 0.49, 'Desastre_Evento_Geodinâmico_Extremo': 0.64, 'Desastre_Evento_Hidrológico_Extremo': 0.45, 'Desastre_Predicted': 'Evento_Geodinâmico_Extremo', 'Desastre_Confidence': 0.64, 'Urgencia_Muito_baixa': 0.6, 'Urgencia_Baixa': 0.63, 'Urgencia_Moderada': 0.67, 'Urgencia_Alta': 0.44, 'Urgencia_Crítica': 0.57, 'Urgencia_Predicted': 'Moderada', 'Urgencia_Confidence': 0.67, 'Urgencia_Score': 0.7677499999999999}, 'entities': [{'text': 'Zona Leste', 'label': 'LOC', 'start_char': 60, 'end_char': 70}, {'text': 'Hospital São Lucas', 'label': 'LOC', 'start_char': 125, 'end_char': 143}, {'text': 'Alguém', 'label': 'MISC', 'start_char': 145, 'end_char': 151}], 'disasterbot_response': 'Erro ao gerar resposta do DisasterBot: File not found: C:\\\\Users\\\\José\\\\Desktop\\\\Projetos Python\\\\global-solution-disasters\\\\Processamento de Linguagem Natural\\\\kbEvento_Geodinâmico_Extremo_Moderada.txt'}\n"
     ]
    }
   ],
   "source": [
    "# No terminal, a partir da raiz do projeto e certificando-se de estar no ambiente python correto, rodar a seguinte linha: \n",
    "# uvicorn \"ProcessamentodeLinguagemNatural.src.api:app\" --reload\n",
    "\n",
    "import requests\n",
    "\n",
    "url = \"http://127.0.0.1:8000/predict\"\n",
    "payload = {\"text\": \"As crianças estão chorando aqui embaixo. Fomos evacuados da Zona Leste após o terremoto. Precisamos dos remédios deixados no Hospital São Lucas. Alguém, por favor, ajude!\"}\n",
    "response = requests.post(url, json=payload)\n",
    "\n",
    "print(response.json())\n",
    "\n",
    "# Você também pode rodar este comando para testar no cmd:\n",
    "# curl -X POST \"http://127.0.0.1:8000/predict\" -H \"Content-Type: application/json\" -Body '{\"text\": \"As crianças estão chorando aqui embaixo. Fomos evacuados da Zona Leste após o terremoto. Precisamos dos remédios deixados no Hospital São Lucas. Alguém, por favor, ajude!\"}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44015c4",
   "metadata": {},
   "source": [
    "# Bônus\n",
    "Incluiremos o pipeline em um front simples do Streamlit em pln_page.py, o qual será deployado na Streamlit Cloud com as outras Global Solutions.\n",
    "\n",
    "Não faremos ali uso da api, a qual não é possível hospedar na Streamlit Cloud."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
